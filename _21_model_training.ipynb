{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _lib.trainer import DocumentEmbeddingType\n",
    "from _lib.trainer import load_corpus, init_document_embedding, train_model, test\n",
    "\n",
    "\n",
    "emb_types = [DocumentEmbeddingType.POOL, DocumentEmbeddingType.RNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-26 03:51:09,419]\u001b[0m Trial 49 finished with value: 0.5431769722814499 and parameters: {'optimizer': 'Adagrad', 'lr': 0.0061190284559545565, 'min_batch_size': 192, 'anneal_factor': 0.1, 'warmup_fraction': 0.6960886177574981, 'hidden_size': 390, 'rnn_layers': 2, 'bidirectional': False, 'dropout': 0.20492127866343263, 'rnn_type': 'LSTM'}. Best is trial 44 with value: 0.5708955223880597.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'optimizer': 'Adagrad', 'lr': 0.030104675841443735, 'min_batch_size': 64, 'anneal_factor': 0.1, 'warmup_fraction': 0.37239158129342714, 'hidden_size': 382, 'rnn_layers': 2, 'bidirectional': False, 'dropout': 0.1594257108834852, 'rnn_type': 'LSTM'}\n",
      "value: 0.5708955223880597\n"
     ]
    }
   ],
   "source": [
    "for vec_fname in ['8', '8_g']:\n",
    "    for emb_type in emb_types:\n",
    "        test('8_typeoftrip_20', vec_fname, emb_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-27 07:39:09,305]\u001b[0m Trial 49 finished with value: 0.5678571428571428 and parameters: {'optimizer': 'Adam', 'lr': 0.00020309470413567372, 'min_batch_size': 160, 'anneal_factor': 0.1, 'warmup_fraction': 0.3537305091984672, 'hidden_size': 352, 'rnn_layers': 2, 'bidirectional': True, 'dropout': 0.3616598713302082, 'rnn_type': 'GRU'}. Best is trial 41 with value: 0.5974489795918367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'optimizer': 'Adam', 'lr': 0.0015753731379671806, 'min_batch_size': 160, 'anneal_factor': 0.1, 'warmup_fraction': 0.018745561493664156, 'hidden_size': 312, 'rnn_layers': 1, 'bidirectional': True, 'dropout': 0.3200865960265571, 'rnn_type': 'GRU'}\n",
      "value: 0.5974489795918367\n"
     ]
    }
   ],
   "source": [
    "for vec_fname in ['9', '9_g']:\n",
    "    for emb_type in emb_types:\n",
    "        test('9_typeoftrip_20', vec_fname, emb_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-28 21:01:07,830]\u001b[0m Trial 49 finished with value: 0.5058043117744611 and parameters: {'optimizer': 'SGD', 'lr': 0.0893505436811484, 'min_batch_size': 32, 'anneal_factor': 0.2, 'warmup_fraction': 0.024267567775304245, 'hidden_size': 190, 'rnn_layers': 5, 'bidirectional': False, 'dropout': 0.27912872014245704, 'rnn_type': 'GRU'}. Best is trial 46 with value: 0.5953565505804311.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'optimizer': 'Adam', 'lr': 0.0011428542164246822, 'min_batch_size': 32, 'anneal_factor': 0.2, 'warmup_fraction': 0.07554823779538865, 'hidden_size': 229, 'rnn_layers': 5, 'bidirectional': False, 'dropout': 0.37528418807671327, 'rnn_type': 'GRU'}\n",
      "value: 0.5953565505804311\n"
     ]
    }
   ],
   "source": [
    "for vec_fname in ['10', '10_g']:\n",
    "    for emb_type in emb_types:\n",
    "        test('10_typeoftrip_20', vec_fname, emb_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEst of the Best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8_typeoftrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from _lib.helper import get_file_paths\n",
    "from _lib.settings import DATA_FLAIR_TESTS_DIR, DATA_FLAIR_CORPUS_DIR, DATA_W2V_KEYED_VECTORS_DIR\n",
    "from _lib.trainer import DocumentEmbeddingType\n",
    "from _lib.trainer import load_corpus, init_document_embedding, train_model, test\n",
    "from flair.embeddings import WordEmbeddings\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "emb_types = [DocumentEmbeddingType.POOL, DocumentEmbeddingType.RNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_runs(resolution, top):\n",
    "    df_bfb_params = pd.DataFrame()\n",
    "\n",
    "    for emb_type in emb_types:\n",
    "        for fpath in get_file_paths(DATA_FLAIR_TESTS_DIR, includes=[emb_type, str(resolution)]):\n",
    "        \n",
    "            df = pd.read_csv(fpath)\n",
    "            df.sort_values(['value'], ascending=False, inplace=True)\n",
    "            df = df[:top]\n",
    "            df = df[[column for column in df.columns if 'params' in column]]\n",
    "            df['params_emb_type'] = emb_type\n",
    "            df['params_graph'] = '_g_' in fpath\n",
    "            df_bfb_params = df_bfb_params.append(df, ignore_index=True)\n",
    "    \n",
    "    return df_bfb_params\n",
    "\n",
    "\n",
    "def run_final_tests(resolution, max_epochs, top=2):\n",
    "    df_bfb_params = get_best_runs(resolution, top)\n",
    "    \n",
    "    df_bfb_params = df_bfb_params.sort_values(['params_emb_type'], ascending=False)\n",
    "\n",
    "    for i, run in df_bfb_params.iterrows():\n",
    "\n",
    "        corpus_dir = f'{resolution}_typeoftrip'\n",
    "        project_name = f\"final_{corpus_dir}\"\n",
    "        label_type = 'mylable'\n",
    "        corpus, label_dict = load_corpus(f\"{DATA_FLAIR_CORPUS_DIR}/{corpus_dir}\", label_type)\n",
    "        glove_embedding = WordEmbeddings(f\"{DATA_W2V_KEYED_VECTORS_DIR}/{resolution}{'_g' if run['params_graph'] else ''}.kv\")\n",
    "\n",
    "        document_embeddings, embed_params = init_document_embedding(\n",
    "            embedding_type=run['params_emb_type'],\n",
    "            glove_embedding=glove_embedding,\n",
    "            fine_tune_mode=run['params_fine_tune_mode'],\n",
    "            pooling=run['params_pooling'],\n",
    "            hidden_size=int(run['params_hidden_size']),\n",
    "            rnn_layers=int(run['params_rnn_layers']),\n",
    "            bidirectional=run['params_bidirectional'],\n",
    "            dropout=run['params_dropout'],\n",
    "            rnn_type=run['params_rnn_type'],\n",
    "        )\n",
    "\n",
    "        wandb_config = {\n",
    "            'emb_type' : run['params_emb_type'],\n",
    "            'graph' : run['params_graph'],\n",
    "            'max_epochs': max_epochs,\n",
    "            'learning_rate': run['params_lr'],\n",
    "            'mini_batch_size': run['params_min_batch_size'],\n",
    "            'optimizer': run['params_optimizer'],\n",
    "            'anneal_factor': run['params_anneal_factor'],\n",
    "            'warmup_fraction': run['params_warmup_fraction']\n",
    "        }\n",
    "\n",
    "        wandb_config.update(embed_params)\n",
    "        \n",
    "        result, trainer, model = train_model(\n",
    "            project_name=project_name,\n",
    "            wandb_config=wandb_config,\n",
    "            document_embeddings=document_embeddings,\n",
    "            label_type=label_type,\n",
    "            label_dict=label_dict,\n",
    "            corpus=corpus,\n",
    "            max_epochs=max_epochs,\n",
    "            learning_rate=run['params_lr'],\n",
    "            mini_batch_size=run['params_min_batch_size'],\n",
    "            optimizer=run['params_optimizer'],\n",
    "            anneal_factor=run['params_anneal_factor'],\n",
    "            warmup_fraction=run['params_warmup_fraction'],\n",
    "            param_selection_mode=False\n",
    "        )\n",
    "\n",
    "        df_bfb_params.at[i, 'value'] = result['test_score']\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    df_bfb_params.to_csv(f\"{DATA_FLAIR_TESTS_DIR}/{project_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 01:00:20,371 Reading data from /media/yyeliseyenka/Zalman Data/lvrobi-gityy/data/flair/corpus/8_typeoftrip\n",
      "2022-05-30 01:00:20,372 Train: /media/yyeliseyenka/Zalman Data/lvrobi-gityy/data/flair/corpus/8_typeoftrip/train.csv\n",
      "2022-05-30 01:00:20,374 Dev: /media/yyeliseyenka/Zalman Data/lvrobi-gityy/data/flair/corpus/8_typeoftrip/dev.csv\n",
      "2022-05-30 01:00:20,375 Test: /media/yyeliseyenka/Zalman Data/lvrobi-gityy/data/flair/corpus/8_typeoftrip/test.csv\n",
      "2022-05-30 01:00:20,531 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28146/28146 [00:07<00:00, 3867.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 01:00:27,939 Corpus contains the labels: mylable (#28146)\n",
      "2022-05-30 01:00:27,939 Created (for label 'mylable') Dictionary with 5 tags: <unk>, hometowork, leisure, other, hometoschool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbjuggler\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/yyeliseyenka/Zalman Data/lvrobi-gityy/wandb/run-20220530_010030-kdskj00w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/bjuggler/final_8_typeoftrip/runs/kdskj00w\" target=\"_blank\">stoic-feather-5</a></strong> to <a href=\"https://wandb.ai/bjuggler/final_8_typeoftrip\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 01:00:37,438 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:37,439 Model: \"TextClassifier(\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings(\n",
      "        '/media/yyeliseyenka/Zalman Data/lvrobi-gityy/data/word2vec/keyed_vectors/8.kv'\n",
      "        (embedding): Embedding(33574, 50)\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (rnn): GRU(50, 181, num_layers=3, batch_first=True)\n",
      "    (dropout): Dropout(p=0.3216712931095337, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=181, out_features=5, bias=True)\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-05-30 01:00:37,440 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:37,441 Corpus: \"Corpus: 28146 train + 9382 dev + 9381 test sentences\"\n",
      "2022-05-30 01:00:37,443 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:37,444 Parameters:\n",
      "2022-05-30 01:00:37,446  - learning_rate: \"0.0094445997326351\"\n",
      "2022-05-30 01:00:37,447  - mini_batch_size: \"256\"\n",
      "2022-05-30 01:00:37,448  - patience: \"3\"\n",
      "2022-05-30 01:00:37,449  - anneal_factor: \"0.5\"\n",
      "2022-05-30 01:00:37,450  - max_epochs: \"100\"\n",
      "2022-05-30 01:00:37,451  - shuffle: \"True\"\n",
      "2022-05-30 01:00:37,452  - train_with_dev: \"False\"\n",
      "2022-05-30 01:00:37,453  - batch_growth_annealing: \"False\"\n",
      "2022-05-30 01:00:37,455 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:37,456 Model training base path: \"resources/final_8_typeoftrip\"\n",
      "2022-05-30 01:00:37,457 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:37,458 Device: cuda:0\n",
      "2022-05-30 01:00:37,459 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:37,460 Embeddings storage mode: None\n",
      "2022-05-30 01:00:37,464 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyeliseyenka/anaconda3/lib/python3.9/site-packages/flair/trainers/trainer.py:65: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 01:00:39,697 epoch 1 - iter 11/110 - loss 0.00643392 - samples/sec: 1498.11 - lr: 0.009445\n",
      "2022-05-30 01:00:41,511 epoch 1 - iter 22/110 - loss 0.00554513 - samples/sec: 1999.35 - lr: 0.009445\n",
      "2022-05-30 01:00:43,371 epoch 1 - iter 33/110 - loss 0.00515484 - samples/sec: 1891.64 - lr: 0.009445\n",
      "2022-05-30 01:00:45,343 epoch 1 - iter 44/110 - loss 0.00497453 - samples/sec: 2062.45 - lr: 0.009445\n",
      "2022-05-30 01:00:47,005 epoch 1 - iter 55/110 - loss 0.00486850 - samples/sec: 2110.36 - lr: 0.009445\n",
      "2022-05-30 01:00:48,847 epoch 1 - iter 66/110 - loss 0.00478727 - samples/sec: 1881.89 - lr: 0.009445\n",
      "2022-05-30 01:00:50,615 epoch 1 - iter 77/110 - loss 0.00473282 - samples/sec: 1995.90 - lr: 0.009445\n",
      "2022-05-30 01:00:52,540 epoch 1 - iter 88/110 - loss 0.00468157 - samples/sec: 1831.02 - lr: 0.009445\n",
      "2022-05-30 01:00:54,418 epoch 1 - iter 99/110 - loss 0.00464144 - samples/sec: 1877.65 - lr: 0.009445\n",
      "2022-05-30 01:00:56,263 epoch 1 - iter 110/110 - loss 0.00461206 - samples/sec: 1914.65 - lr: 0.009445\n",
      "2022-05-30 01:00:56,357 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 01:00:56,358 EPOCH 1 done: loss 0.0046 - lr 0.0094446\n",
      "2022-05-30 01:01:04,132 DEV : loss 0.004290395881980658 - f1-score (micro avg)  0.5456\n",
      "2022-05-30 01:01:12,898 TEST : loss 0.004319268744438887 - f1-score (micro avg)  0.545\n",
      "2022-05-30 01:01:14,977 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 01:01:14,979 saving best model\n",
      "2022-05-30 01:01:15,064 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_final_tests(8, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_final_tests(9, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_final_tests(10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_final_tests"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bf1d6a3a2ce20794dfe5dd94238bf73575b92dbd1ed6b7165e90d0a813ac81c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
