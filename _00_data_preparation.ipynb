{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from _lib.data_preparation import remove_substandard_trips, df_calc_basic, df_join_generic_with_gps, read_gpx, calc_context\n",
    "from _lib.data_preparation_help import val2year, val2zip, val2utf8\n",
    "from _lib.settings import DATA_AFTER_PREPARATION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FR Amiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _lib.settings import DATA_ORIGIN_AMIENS_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'ami'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2780/3928128295.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ami16 = pd.read_csv(f'{DATA_ORIGIN_AMIENS_DIR}/detail_2016.csv', encoding='windows-1250')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (424910, 8)\n",
      "Removed 0 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 424910/424910 [00:01<00:00, 369982.59it/s]\n",
      "end: 100%|██████████| 424910/424910 [00:01<00:00, 352194.64it/s]\n",
      "distance: 100%|██████████| 424910/424910 [00:01<00:00, 232850.11it/s]\n",
      "duration: 100%|██████████| 424910/424910 [00:01<00:00, 354152.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (305314, 13)\n"
     ]
    }
   ],
   "source": [
    "df_ami16 = pd.read_csv(f'{DATA_ORIGIN_AMIENS_DIR}/detail_2016.csv', encoding='windows-1250')\n",
    "\n",
    "print('Shape before: ', df_ami16.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_ami16.columns = [cname.replace(' ', '').lower() for cname in df_ami16.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_ami16['tripid'] = SHORT_NAME + df_ami16['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "df_ami16['timestamp'] = df_ami16['timestamp'].apply(lambda x: datetime.fromtimestamp(float(x)).timestamp() )\n",
    "\n",
    "df_ami16 = df_ami16.astype({'latitude': 'float', 'longitude': 'float'})\n",
    "\n",
    "df_ami16 = remove_substandard_trips(df_ami16)\n",
    "df_ami16 = df_calc_basic(df_ami16)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_ami16 = df_ami16[(df_ami16['distance'] != 0) | (df_ami16['end']) | (df_ami16['start'])]\n",
    "\n",
    "print('Shape after: ', df_ami16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (2107, 11)\n",
      "Shape after:  (1749, 18)\n"
     ]
    }
   ],
   "source": [
    "df_ami16_generic = pd.read_csv(f'{DATA_ORIGIN_AMIENS_DIR}/generic_2016.csv', encoding='windows-1250')\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_ami16_generic.columns = [cname.replace(' ', '').lower() for cname in df_ami16_generic.columns]\n",
    "\n",
    "df_ami16_generic['tripid'] = SHORT_NAME + df_ami16_generic['tripid'].apply(lambda x: x.replace(' ', ''))\n",
    "df_ami16_generic['distance'] = df_ami16_generic['distance'].astype(float)\n",
    "df_ami16_generic['valid'] = df_ami16_generic[df_ami16_generic['ecc'].notna()]['ecc'].apply(lambda x: False if x == 0 else True)\n",
    "df_ami16_generic['avgspeed'] = df_ami16_generic['avgspeed'].astype(float)\n",
    "df_ami16_generic['tracktype'] = df_ami16_generic[df_ami16_generic['tracktype'].notna()]['tracktype'].apply(val2utf8)\n",
    "df_ami16_generic['male'] = df_ami16_generic[df_ami16_generic['sex'].notna()]['sex'].apply(lambda x: True if str(x).lower() == 'm' else (False if str(x).lower() == 'f' else float('nan')))\n",
    "df_ami16_generic['yearofbirth'] = df_ami16_generic['year'].apply(val2year)\n",
    "df_ami16_generic['profession'] = df_ami16_generic[df_ami16_generic['profession'].notna()]['profession'].apply(val2utf8)\n",
    "df_ami16_generic['frequentuser'] = df_ami16_generic[df_ami16_generic['frequentuser'].notna()]['frequentuser'].apply(lambda x: False if x.lower() in ['no', 'non'] else False)\n",
    "df_ami16_generic['zip'] = df_ami16_generic[df_ami16_generic['zip'].notna()]['zip'].apply(val2zip)\n",
    "df_ami16_generic['source'] = df_ami16_generic[df_ami16_generic['source'].notna()]['source'].apply(val2utf8)\n",
    "df_ami16_generic['typeofbike'] = df_ami16_generic[df_ami16_generic['typeofbike'].notna()]['typeofbike'].apply(val2utf8)\n",
    "df_ami16_generic['typeoftrip'] = df_ami16_generic[df_ami16_generic['tipeoftrip'].notna()]['tipeoftrip'].apply(val2utf8)\n",
    "\n",
    "df_ami16_generic.drop(['timestamp', 'startdt', 'ecc', 'sex', 'year', 'tipeoftrip', 'distance', 'avgspeed'], axis=1, inplace=True)\n",
    "\n",
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_ami16_generic.shape)\n",
    "\n",
    "df_ami16_generic = df_join_generic_with_gps(df_ami16_generic, df_ami16)\n",
    "\n",
    "print('Shape after: ', df_ami16_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (904274, 8)\n",
      "Removed 54 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 860377/860377 [00:02<00:00, 386277.49it/s]\n",
      "end: 100%|██████████| 860377/860377 [00:02<00:00, 359702.98it/s]\n",
      "distance: 100%|██████████| 860377/860377 [00:04<00:00, 207241.22it/s]\n",
      "duration: 100%|██████████| 860377/860377 [00:02<00:00, 319711.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (859306, 13)\n"
     ]
    }
   ],
   "source": [
    "df_ami17 = pd.read_csv(f'{DATA_ORIGIN_AMIENS_DIR}/detail_2017.csv', encoding='windows-1250', sep=';')\n",
    "\n",
    "print('Shape before: ', df_ami17.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_ami17.columns = [cname.replace(' ', '').lower() for cname in df_ami17.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_ami17['tripid'] = SHORT_NAME + df_ami17['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "df_ami17['timestamp'] = df_ami17['timestamp'].apply(lambda x: datetime.fromtimestamp(float(x)).timestamp() )\n",
    "df_ami17['latitude'] = df_ami17['latitude'].str.replace(',', '.').astype(float)\n",
    "df_ami17['longitude'] = df_ami17['longitude'].str.replace(',', '.').astype(float)\n",
    "df_ami17['altitude'] = df_ami17['altitude'].astype(float)\n",
    "\n",
    "df_ami17 = remove_substandard_trips(df_ami17)\n",
    "df_ami17 = df_calc_basic(df_ami17)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_ami17 = df_ami17[(df_ami17['distance'] != 0) | (df_ami17['end']) | (df_ami17['start'])]\n",
    "\n",
    "print('Shape after: ', df_ami17.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (2350, 6)\n",
      "Shape after:  (1621, 13)\n"
     ]
    }
   ],
   "source": [
    "df_ami17_generic = pd.read_csv(f'{DATA_ORIGIN_AMIENS_DIR}/generic_2017.csv', encoding='windows-1250', sep=';')\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_ami17_generic.columns = [cname.replace(' ', '').lower() for cname in df_ami17_generic.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_ami17_generic['tripid'] = SHORT_NAME + df_ami17_generic['tripid'].astype(str).replace(' ', '')\n",
    "df_ami17_generic['avgspeed'] = df_ami17_generic['avgspeed'].str.replace(',', '.').astype(float)\n",
    "df_ami17_generic['distance'] = df_ami17_generic['totallength'].str.replace(',', '.').astype(float)\n",
    "df_ami17_generic['valid'] = df_ami17_generic['valid'].apply(lambda x: False if str(x).lower() == 'no' else True)\n",
    "df_ami17_generic['male'] = df_ami17_generic[df_ami17_generic['sex'].notna()]['sex'].apply(lambda x: True if str(x).lower() == 'male' else (False if str(x).lower() == 'female' else float('nan')))\n",
    "df_ami17_generic['yearofbirth'] = df_ami17_generic['yearofbirth'].apply(val2year)\n",
    "df_ami17_generic['typeofbike'] = df_ami17_generic[df_ami17_generic['typeofbike'].notna()]['typeofbike'].apply(val2utf8)\n",
    "df_ami17_generic['typeoftrip'] = df_ami17_generic[df_ami17_generic['typeoftrip'].notna()]['typeoftrip'].apply(val2utf8)\n",
    "\n",
    "df_ami17_generic.drop(['uploaded', 'sex', 'timestamp', 'startdate', 'starttime', 'duration', 'maxspeed', 'totallength', 'lengthvalid', 'avgspeed', 'distance'], axis=1, inplace=True)\n",
    "\n",
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_ami17_generic.shape)\n",
    "\n",
    "df_ami17_generic = df_join_generic_with_gps(df_ami17_generic, df_ami17)\n",
    "\n",
    "print('Shape after: ', df_ami17_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before. 2016: (305314, 13) 2017: (859306, 13)\n",
      "Shape after. 2016: (273082, 5) 2017: (762428, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before. 2016:', df_ami16.shape, '2017:', df_ami17.shape)\n",
    "\n",
    "df_ami16 = df_ami16[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_ami16 = df_ami16[df_ami16['tripid'].isin(df_ami16_generic['tripid'].tolist())]\n",
    "\n",
    "df_ami17 = df_ami17[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_ami17 = df_ami17[df_ami17['tripid'].isin(df_ami17_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after. 2016:', df_ami16.shape, '2017:', df_ami17.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before. 2015: (1749, 18) 2016: (1621, 13)\n",
      "Shape before. 2015: (1749, 15) 2016: (1621, 12)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before. 2015:', df_ami16_generic.shape, '2016:', df_ami17_generic.shape)\n",
    "\n",
    "df_ami16_generic = df_ami16_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'tracktype', 'source', 'profession', 'male', 'frequentuser', 'zip', 'yearofbirth', 'valid']]\n",
    "\n",
    "df_ami17_generic = df_ami17_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'typeofbike', 'typeoftrip', 'male', 'yearofbirth', 'valid']]\n",
    "\n",
    "print('Shape before. 2015:', df_ami16_generic.shape, '2016:', df_ami17_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets concatenaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035510 entries, 0 to 1035509\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   tripid     1035510 non-null  object \n",
      " 1   latitude   1035510 non-null  float64\n",
      " 2   longitude  1035510 non-null  float64\n",
      " 3   timestamp  1035510 non-null  float64\n",
      " 4   start      1035510 non-null  bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 32.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ami = pd.concat([df_ami16, df_ami17], ignore_index=True)\n",
    "df_ami.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370 entries, 0 to 3369\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tripid                   3370 non-null   object \n",
      " 1   speedmax                 3370 non-null   float64\n",
      " 2   speedavg_excluding_time  3370 non-null   float64\n",
      " 3   speedavg_over_time       3370 non-null   float64\n",
      " 4   distance                 3370 non-null   float64\n",
      " 5   startts                  3370 non-null   float64\n",
      " 6   endts                    3370 non-null   float64\n",
      " 7   tracktype                1749 non-null   object \n",
      " 8   source                   1749 non-null   object \n",
      " 9   profession               1292 non-null   object \n",
      " 10  male                     1849 non-null   object \n",
      " 11  frequentuser             1749 non-null   object \n",
      " 12  zip                      845 non-null    object \n",
      " 13  yearofbirth              1946 non-null   object \n",
      " 14  valid                    3370 non-null   bool   \n",
      " 15  typeofbike               1130 non-null   object \n",
      " 16  typeoftrip               1141 non-null   object \n",
      "dtypes: bool(1), float64(6), object(10)\n",
      "memory usage: 424.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ami_generic = pd.concat([df_ami16_generic, df_ami17_generic], ignore_index=True)\n",
    "df_ami_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ami.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_ami_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL Wroclaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from _lib.settings import DATA_ORIGIN_WROCLAW_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'wro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2780/3404425056.py:1: DtypeWarning: Columns (1,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_wro15 = pd.read_csv(f'{DATA_ORIGIN_WROCLAW_DIR}/detail_2015.csv', encoding='windows-1250', skiprows=[9627453])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (20931869, 9)\n",
      "Removed 21 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "timestamp: 100%|██████████| 20931208/20931208 [00:54<00:00, 382387.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 20930880/20930880 [01:00<00:00, 348723.59it/s]\n",
      "end: 100%|██████████| 20930880/20930880 [01:03<00:00, 330361.51it/s]\n",
      "distance: 100%|██████████| 20930880/20930880 [01:55<00:00, 180797.93it/s]\n",
      "duration: 100%|██████████| 20930880/20930880 [01:23<00:00, 250827.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (16334748, 15)\n"
     ]
    }
   ],
   "source": [
    "df_wro15 = pd.read_csv(f'{DATA_ORIGIN_WROCLAW_DIR}/detail_2015.csv', encoding='windows-1250', skiprows=[9627453])\n",
    "\n",
    "print('Shape before: ', df_wro15.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_wro15.columns = [cname.replace(' ', '').lower() for cname in df_wro15.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_wro15['tripid'] = SHORT_NAME + df_wro15['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "df_wro15 = df_wro15.astype({'latitude': 'float', 'longitude': 'float'})\n",
    "df_wro15 = remove_substandard_trips(df_wro15)\n",
    "\n",
    "tqdm.pandas(desc='timestamp')\n",
    "df_wro15['timestamp'] = df_wro15['timestamp'].progress_apply(lambda x: float('nan') if str(x).lower() in ['false', 'nan'] else datetime.fromtimestamp(float(x)).timestamp())\n",
    "\n",
    "df_wro15 = remove_substandard_trips(df_wro15)\n",
    "df_wro15 = df_calc_basic(df_wro15)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_wro15 = df_wro15[(df_wro15['distance'] != 0) | (df_wro15['end']) | (df_wro15['start'])]\n",
    "\n",
    "print('Shape after: ', df_wro15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (49941, 9)\n",
      "Shape after:  (49154, 16)\n"
     ]
    }
   ],
   "source": [
    "df_wro15_generic = pd.read_csv(f'{DATA_ORIGIN_WROCLAW_DIR}/generic_2015.csv')\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_wro15_generic.columns = [cname.replace(' ', '').lower() for cname in df_wro15_generic.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_wro15_generic['tripid'] = SHORT_NAME + df_wro15_generic['tripid'].apply(lambda id: id.replace(' ', ''))\n",
    "df_wro15_generic['distance'] = df_wro15_generic['distance'].astype(float)\n",
    "df_wro15_generic['valid'] = df_wro15_generic[df_wro15_generic['ecc'].notna()]['ecc'].apply(lambda x: False if x == 0 else True)\n",
    "df_wro15_generic['avgspeed'] = df_wro15_generic['avgspeed'].astype(float)\n",
    "df_wro15_generic['tracktype'] = df_wro15_generic[df_wro15_generic['tracktype'].notna()]['tracktype'].apply(val2utf8)\n",
    "df_wro15_generic['male'] = df_wro15_generic[df_wro15_generic['sex'].notna()]['sex'].apply(lambda x: True if str(x).lower() == 'm' else (False if str(x).lower() == 'f' else float('nan')))\n",
    "df_wro15_generic['yearofbirth'] = df_wro15_generic['year'].apply(val2year)\n",
    "df_wro15_generic['profession'] = df_wro15_generic[df_wro15_generic['profession'].notna()]['profession'].apply(val2utf8)\n",
    "df_wro15_generic['frequentuser'] = df_wro15_generic[df_wro15_generic['frequentuser'].notna()]['frequentuser'].apply(lambda x: False if x.lower() == 'no' else True)\n",
    "df_wro15_generic['zip'] = df_wro15_generic[df_wro15_generic['zip'].notna()]['zip'].apply(val2zip)\n",
    "df_wro15_generic['source'] = df_wro15_generic[df_wro15_generic['source'].notna()]['source'].apply(val2utf8)\n",
    "\n",
    "df_wro15_generic.drop(['timestamp', 'startdt', 'ecc', 'sex', 'year', 'distance', 'avgspeed'], axis=1, inplace=True)\n",
    "\n",
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_wro15_generic.shape)\n",
    "\n",
    "df_wro15_generic = df_join_generic_with_gps(df_wro15_generic, df_wro15)\n",
    "\n",
    "print('Shape after: ', df_wro15_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2780/2463794659.py:1: DtypeWarning: Columns (4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_wro16 = pd.read_csv(f'{DATA_ORIGIN_WROCLAW_DIR}/detail_2016.csv', encoding='windows-1250', skiprows=[11184484])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (22455984, 8)\n",
      "Removed 2 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "timestamp: 100%|██████████| 22453198/22453198 [01:06<00:00, 336442.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 22453198/22453198 [01:05<00:00, 345356.30it/s]\n",
      "end: 100%|██████████| 22453198/22453198 [01:03<00:00, 351159.06it/s]\n",
      "distance: 100%|██████████| 22453198/22453198 [01:54<00:00, 196891.51it/s]\n",
      "duration: 100%|██████████| 22453198/22453198 [01:06<00:00, 338635.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (18122010, 14)\n"
     ]
    }
   ],
   "source": [
    "df_wro16 = pd.read_csv(f'{DATA_ORIGIN_WROCLAW_DIR}/detail_2016.csv', encoding='windows-1250', skiprows=[11184484])\n",
    "\n",
    "print('Shape before: ', df_wro16.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_wro16.columns = [cname.replace(' ', '').lower() for cname in df_wro16.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_wro16['tripid'] = SHORT_NAME + df_wro16['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "df_wro16 = df_wro16.astype({'latitude': 'float', 'longitude': 'float'})\n",
    "df_wro16 = remove_substandard_trips(df_wro16)\n",
    "\n",
    "tqdm.pandas(desc='timestamp')\n",
    "df_wro16['timestamp'] = df_wro16['timestamp'].progress_apply(lambda x: float('nan') if str(x).lower() in ['false', 'nan'] else datetime.fromtimestamp(float(x)).timestamp() )\n",
    "\n",
    "df_wro16 = remove_substandard_trips(df_wro16)\n",
    "df_wro16 = df_calc_basic(df_wro16)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_wro16 = df_wro16[(df_wro16['distance'] != 0) | (df_wro16['end']) | (df_wro16['start'])]\n",
    "\n",
    "print('Shape after: ', df_wro16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (42384, 12)\n",
      "Shape after:  (41271, 19)\n"
     ]
    }
   ],
   "source": [
    "df_wro16_generic = pd.read_csv(f'{DATA_ORIGIN_WROCLAW_DIR}/generic_2016.csv')\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_wro16_generic.columns = [cname.replace(' ', '').lower() for cname in df_wro16_generic.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_wro16_generic['tripid'] = SHORT_NAME + df_wro16_generic['tripid'].apply(lambda x: x.replace(' ', ''))\n",
    "df_wro16_generic['distance'] = df_wro16_generic['distance'].astype(float)\n",
    "df_wro16_generic['valid'] = df_wro16_generic[df_wro16_generic['ecc'].notna()]['ecc'].apply(lambda x: False if x == 0 else True)\n",
    "df_wro16_generic['avgspeed'] = df_wro16_generic['avgspeed'].astype(float)\n",
    "df_wro16_generic['tracktype'] = df_wro16_generic[df_wro16_generic['tracktype'].notna()]['tracktype'].apply(val2utf8)\n",
    "df_wro16_generic['male'] = df_wro16_generic[df_wro16_generic['sex'].notna()]['sex'].apply(lambda x: True if str(x).lower() == 'm' else (False if str(x).lower() == 'f' else float('nan')))\n",
    "df_wro16_generic['yearofbirth'] = df_wro16_generic['year'].apply(val2year)\n",
    "df_wro16_generic['profession'] = df_wro16_generic[df_wro16_generic['profession'].notna()]['profession'].apply(val2utf8)\n",
    "df_wro16_generic['frequentuser'] = df_wro16_generic[df_wro16_generic['frequentuser'].notna()]['frequentuser'].apply(lambda x: False if x.lower() in ['no', 'nie'] else False)\n",
    "df_wro16_generic['zip'] = df_wro16_generic[df_wro16_generic['zip'].notna()]['zip'].apply(val2zip)\n",
    "df_wro16_generic['source'] = df_wro16_generic[df_wro16_generic['source'].notna()]['source'].apply(val2utf8)\n",
    "df_wro16_generic['typeofbike'] = df_wro16_generic[df_wro16_generic['typeofbike'].notna()]['typeofbike'].apply(val2utf8)\n",
    "df_wro16_generic['typeoftrip'] = df_wro16_generic[df_wro16_generic['tipeoftrip'].notna()]['tipeoftrip'].apply(val2utf8)\n",
    "\n",
    "df_wro16_generic.drop(['timestamp', 'startdt', 'ecc', 'sex', 'year', 'distance', 'avgspeed'], axis=1, inplace=True)\n",
    "\n",
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_wro16_generic.shape)\n",
    "\n",
    "df_wro16_generic = df_join_generic_with_gps(df_wro16_generic, df_wro16)\n",
    "\n",
    "print('Shape after: ', df_wro16_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before. 2015: (16334748, 15) 2016: (18122010, 14)\n",
      "Shape after. 2015: (16144800, 5) 2016: (17875093, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before. 2015:', df_wro15.shape, '2016:', df_wro16.shape)\n",
    "\n",
    "df_wro15 = df_wro15[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_wro15 = df_wro15[df_wro15['tripid'].isin(df_wro15_generic['tripid'].tolist())]\n",
    "\n",
    "df_wro16 = df_wro16[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_wro16 = df_wro16[df_wro16['tripid'].isin(df_wro16_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after. 2015:', df_wro15.shape, '2016:', df_wro16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before. 2015: (49154, 16) 2016: (41271, 19)\n",
      "Shape before. 2015: (49154, 15) 2016: (41271, 17)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before. 2015:', df_wro15_generic.shape, '2016:', df_wro16_generic.shape)\n",
    "\n",
    "df_wro15_generic = df_wro15_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'tracktype', 'source', 'profession', 'male', 'frequentuser', 'zip', 'yearofbirth', 'valid']]\n",
    "\n",
    "df_wro16_generic = df_wro16_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'tracktype', 'typeofbike', 'typeoftrip', 'source', 'profession', 'male', 'frequentuser', 'zip', 'yearofbirth', 'valid']]\n",
    "\n",
    "print('Shape before. 2015:', df_wro15_generic.shape, '2016:', df_wro16_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets concatenaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34019893 entries, 0 to 34019892\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   tripid     object \n",
      " 1   latitude   float64\n",
      " 2   longitude  float64\n",
      " 3   timestamp  float64\n",
      " 4   start      bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df_wro = pd.concat([df_wro15, df_wro16], ignore_index=True)\n",
    "df_wro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90425 entries, 0 to 90424\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tripid                   90425 non-null  object \n",
      " 1   speedmax                 90425 non-null  float64\n",
      " 2   speedavg_excluding_time  90425 non-null  float64\n",
      " 3   speedavg_over_time       90425 non-null  float64\n",
      " 4   distance                 90425 non-null  float64\n",
      " 5   startts                  90425 non-null  float64\n",
      " 6   endts                    90425 non-null  float64\n",
      " 7   tracktype                90425 non-null  object \n",
      " 8   source                   90425 non-null  object \n",
      " 9   profession               67403 non-null  object \n",
      " 10  male                     79218 non-null  object \n",
      " 11  frequentuser             90404 non-null  object \n",
      " 12  zip                      54714 non-null  object \n",
      " 13  yearofbirth              74237 non-null  object \n",
      " 14  valid                    90425 non-null  bool   \n",
      " 15  typeofbike               20551 non-null  object \n",
      " 16  typeoftrip               20532 non-null  object \n",
      "dtypes: bool(1), float64(6), object(10)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_wro_generic = pd.concat([df_wro15_generic, df_wro16_generic], ignore_index=True)\n",
    "df_wro_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wro.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_wro_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE Orebro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _lib.settings import DATA_ORIGIN_OREBRO_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'ore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2156/2156 [01:03<00:00, 33.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((648689, 5), (2156, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ore15, df_ore15_generic = read_gpx(f'{DATA_ORIGIN_OREBRO_DIR}/2015', SHORT_NAME)\n",
    "\n",
    "df_ore15.shape, df_ore15_generic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (648689, 5)\n",
      "Removed 9 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 648398/648398 [00:01<00:00, 365893.04it/s]\n",
      "end: 100%|██████████| 648398/648398 [00:01<00:00, 389275.78it/s]\n",
      "distance: 100%|██████████| 648398/648398 [00:02<00:00, 234017.33it/s]\n",
      "duration: 100%|██████████| 648398/648398 [00:01<00:00, 358234.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (512008, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before: ', df_ore15.shape)\n",
    "\n",
    "df_ore15 = remove_substandard_trips(df_ore15)\n",
    "df_ore15 = df_calc_basic(df_ore15)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_ore15 = df_ore15[(df_ore15['distance'] != 0) | (df_ore15['end']) | (df_ore15['start'])]\n",
    "\n",
    "print('Shape after: ', df_ore15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (2156, 3)\n",
      "Shape after:  (2110, 10)\n"
     ]
    }
   ],
   "source": [
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_ore15_generic.shape)\n",
    "\n",
    "df_ore15_generic = df_join_generic_with_gps(df_ore15_generic, df_ore15)\n",
    "\n",
    "print('Shape after: ', df_ore15_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7992/7992 [00:03<00:00, 2089.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 6), (0, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ore16, df_ore16_generic = read_gpx(f'{DATA_ORIGIN_OREBRO_DIR}/2016', SHORT_NAME)\n",
    "\n",
    "df_ore16 = remove_substandard_trips(df_ore16)\n",
    "\n",
    "df_ore16.shape, df_ore16_generic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Shape before: ', df_ore16.shape)\n",
    "\n",
    "# df_ore16 = remove_substandard_trips(df_ore16)\n",
    "# df_ore16 = df_calc_basic(df_ore16)\n",
    "\n",
    "# ''' Removing points with 0 distance passed '''\n",
    "# df_ore16 = df_ore16[(df_ore16['distance'] != 0) | (df_ore16['end']) | (df_ore16['start'])]\n",
    "\n",
    "# print('Shape after: ', df_ore16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Joinig generic data with gps data '''\n",
    "# print('Shape before: ', df_ore16_generic.shape)\n",
    "\n",
    "# df_ore16_generic = df_join_generic_with_gps(df_ore16_generic, df_ore16)\n",
    "\n",
    "# print('Shape after: ', df_ore16_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (512008, 12)\n",
      "Shape after: (509177, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before:', df_ore15.shape)\n",
    "\n",
    "df_ore15 = df_ore15[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_ore15 = df_ore15[df_ore15['tripid'].isin(df_ore15_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after:', df_ore15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (2110, 10)\n",
      "Shape after: (2110, 8)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before:', df_ore15_generic.shape)\n",
    "\n",
    "df_ore15_generic = df_ore15_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'email']]\n",
    "\n",
    "print('Shape after:', df_ore15_generic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 509177 entries, 0 to 648397\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   tripid     509177 non-null  object \n",
      " 1   latitude   509177 non-null  float64\n",
      " 2   longitude  509177 non-null  float64\n",
      " 3   timestamp  509177 non-null  float64\n",
      " 4   start      509177 non-null  bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 19.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ore15.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2110 entries, 0 to 2109\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tripid                   2110 non-null   object \n",
      " 1   speedmax                 2110 non-null   float64\n",
      " 2   speedavg_excluding_time  2110 non-null   float64\n",
      " 3   speedavg_over_time       2110 non-null   float64\n",
      " 4   distance                 2110 non-null   float64\n",
      " 5   startts                  2110 non-null   float64\n",
      " 6   endts                    2110 non-null   float64\n",
      " 7   email                    2110 non-null   object \n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 132.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ore15_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ore15.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_ore15_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE Oldenburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from _lib.settings import DATA_ORIGIN_OLDENBURG_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'old'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV files 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1181/1181 [01:37<00:00, 12.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(908080, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpaths = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(f'{DATA_ORIGIN_OLDENBURG_DIR}/2020'):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".csv\"):\n",
    "            fpaths.append(os.path.join(dirpath, file))\n",
    "\n",
    "id, lat, lon, ts = [], [], [], []\n",
    "\n",
    "for fpath in tqdm(fpaths):\n",
    "    tripid = SHORT_NAME + fpath[:-4].split('-')[-1]\n",
    "    df_trip = pd.read_csv(fpath, sep=';')\n",
    "    df_trip['timestamp'] = pd.to_datetime(df_trip['measured_date'])\n",
    "    df_trip['timestamp'] = df_trip['timestamp'].apply(lambda x: datetime.timestamp(x))\n",
    "    \n",
    "    id = id + [tripid] * df_trip.shape[0]\n",
    "    lat = lat + df_trip['latitude'].tolist()\n",
    "    lon = lon + df_trip['longitude'].tolist()\n",
    "    ts = ts + df_trip['timestamp'].tolist()\n",
    "\n",
    "df_old = pd.DataFrame(np.array([id, lat, lon, ts]).T, columns=['tripid', 'latitude', 'longitude', 'timestamp'])\n",
    "df_old = df_old.astype({'latitude': 'float', 'longitude': 'float', 'timestamp': 'float'})\n",
    "\n",
    "df_old.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (908080, 4)\n",
      "Removed 146 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 732216/732216 [00:01<00:00, 377188.06it/s]\n",
      "end: 100%|██████████| 732216/732216 [00:01<00:00, 385974.73it/s]\n",
      "distance: 100%|██████████| 732216/732216 [00:02<00:00, 248779.27it/s]\n",
      "duration: 100%|██████████| 732216/732216 [00:02<00:00, 360947.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (731660, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before: ', df_old.shape)\n",
    "\n",
    "df_old = remove_substandard_trips(df_old)\n",
    "df_old = df_calc_basic(df_old)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_old = df_old[(df_old['distance'] != 0) | (df_old['end']) | (df_old['start'])]\n",
    "\n",
    "print('Shape after: ', df_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (1034, 7)\n",
      "Shape after:  (1034, 8)\n"
     ]
    }
   ],
   "source": [
    "df_old_generic = calc_context(df_old)\n",
    "\n",
    "print('Shape before: ', df_old_generic.shape)\n",
    "\n",
    "df_old_generic.drop_duplicates(subset=list(set(df_old_generic.columns.tolist()) - set(['startts', 'endts'])), keep='first', inplace=True)\n",
    "\n",
    "df_old_generic = df_old_generic.reset_index(inplace=False)\n",
    "\n",
    "print('Shape after: ', df_old_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (731660, 11)\n",
      "Shape after: (731659, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before:', df_old.shape)\n",
    "\n",
    "df_old = df_old[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_old = df_old[df_old['tripid'].isin(df_old_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after:', df_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (1034, 8)\n",
      "Shape after: (1034, 7)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before:', df_old_generic.shape)\n",
    "\n",
    "df_old_generic = df_old_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts']]\n",
    "\n",
    "print('Shape after:', df_old_generic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 731659 entries, 0 to 732215\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   tripid     731659 non-null  object \n",
      " 1   latitude   731659 non-null  float64\n",
      " 2   longitude  731659 non-null  float64\n",
      " 3   timestamp  731659 non-null  float64\n",
      " 4   start      731659 non-null  bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_old.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1034 entries, 0 to 1033\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tripid                   1034 non-null   object \n",
      " 1   speedmax                 1034 non-null   float64\n",
      " 2   speedavg_excluding_time  1034 non-null   float64\n",
      " 3   speedavg_over_time       1034 non-null   float64\n",
      " 4   distance                 1034 non-null   float64\n",
      " 5   startts                  1034 non-null   float64\n",
      " 6   endts                    1034 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 56.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_old_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_old_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from _lib.settings import DATA_ORIGIN_BERLIN_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'ber'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files 2020 - 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22931/22931 [03:04<00:00, 124.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12977703, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpaths = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(f'{DATA_ORIGIN_BERLIN_DIR}/2020_2021'):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\"\"):\n",
    "            fpaths.append(os.path.join(dirpath, file))\n",
    "\n",
    "id, lat, lon, ts = [], [], [], []\n",
    "\n",
    "for fpath in tqdm(fpaths):\n",
    "    tripid = SHORT_NAME + fpath.split('/')[-1].split('-')[-1]\n",
    "    with open(fpath) as fr:\n",
    "        Lines = fr.readlines()\n",
    "        begin = False\n",
    "        for line in Lines:\n",
    "            if not begin:\n",
    "                begin = 'lat,lon,X,Y,Z,timeStamp' in line\n",
    "            else:\n",
    "                lline = line.split(',')\n",
    "                if lline[0] != '':\n",
    "                    id.append(tripid)\n",
    "                    lat.append(lline[0])\n",
    "                    lon.append(lline[1])\n",
    "                    ts.append(lline[5][:-3] + '.' + lline[5][-3:])\n",
    "\n",
    "df_ber = pd.DataFrame(np.array([id, lat, lon, ts]).T, columns=['tripid', 'latitude', 'longitude', 'timestamp'])\n",
    "df_ber = df_ber.astype({'latitude': 'float', 'longitude': 'float', 'timestamp': 'float'})\n",
    "\n",
    "df_ber.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (12977703, 4)\n",
      "Removed 0 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 12977703/12977703 [00:32<00:00, 393443.95it/s]\n",
      "end: 100%|██████████| 12977703/12977703 [00:32<00:00, 395917.61it/s]\n",
      "distance: 100%|██████████| 12977703/12977703 [00:54<00:00, 237442.42it/s]\n",
      "duration: 100%|██████████| 12977703/12977703 [00:36<00:00, 360437.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (10923799, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before: ', df_ber.shape)\n",
    "\n",
    "df_ber = remove_substandard_trips(df_ber)\n",
    "df_ber = df_calc_basic(df_ber)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_ber = df_ber[(df_ber['distance'] != 0) | (df_ber['end']) | (df_ber['start'])]\n",
    "\n",
    "print('Shape after: ', df_ber.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (22886, 7)\n",
      "Shape after:  (22544, 8)\n"
     ]
    }
   ],
   "source": [
    "df_ber_generic = calc_context(df_ber)\n",
    "\n",
    "print('Shape before: ', df_ber_generic.shape)\n",
    "\n",
    "df_ber_generic.drop_duplicates(subset=list(set(df_ber_generic.columns.tolist()) - set(['startts', 'endts'])), keep='first', inplace=True)\n",
    "\n",
    "df_ber_generic = df_ber_generic.reset_index(inplace=False)\n",
    "\n",
    "print('Shape after: ', df_ber_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (10923799, 11)\n",
      "Shape after: (10734646, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before:', df_ber.shape)\n",
    "\n",
    "df_ber = df_ber[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_ber = df_ber[df_ber['tripid'].isin(df_ber_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after:', df_ber.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (22544, 8)\n",
      "Shape after: (22544, 7)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before:', df_ber_generic.shape)\n",
    "\n",
    "df_ber_generic = df_ber_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts']]\n",
    "\n",
    "print('Shape after:', df_ber_generic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10734646 entries, 0 to 12976110\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   tripid     object \n",
      " 1   latitude   float64\n",
      " 2   longitude  float64\n",
      " 3   timestamp  float64\n",
      " 4   start      bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 419.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ber.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22544 entries, 0 to 22543\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tripid                   22544 non-null  object \n",
      " 1   speedmax                 22544 non-null  float64\n",
      " 2   speedavg_excluding_time  22544 non-null  float64\n",
      " 3   speedavg_over_time       22544 non-null  float64\n",
      " 4   distance                 22544 non-null  float64\n",
      " 5   startts                  22544 non-null  float64\n",
      " 6   endts                    22544 non-null  float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ber_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ber.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_ber_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL Gdansk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from _lib.settings import DATA_ORIGIN_GDANSK_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'gda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2780/1703542522.py:1: DtypeWarning: Columns (1,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_gda15 = pd.read_csv(f'{DATA_ORIGIN_GDANSK_DIR}/detail_2015.csv', encoding='windows-1250')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (26762382, 9)\n",
      "Removed 21 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "timestamp: 100%|██████████| 26759422/26759422 [01:01<00:00, 434617.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 26754447/26754447 [01:23<00:00, 319376.76it/s]\n",
      "end: 100%|██████████| 26754447/26754447 [01:08<00:00, 388302.11it/s]\n",
      "distance: 100%|██████████| 26754447/26754447 [02:05<00:00, 213646.51it/s]\n",
      "duration: 100%|██████████| 26754447/26754447 [01:14<00:00, 357671.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (22495726, 15)\n"
     ]
    }
   ],
   "source": [
    "df_gda15 = pd.read_csv(f'{DATA_ORIGIN_GDANSK_DIR}/detail_2015.csv', encoding='windows-1250')\n",
    "\n",
    "print('Shape before: ', df_gda15.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_gda15.columns = [cname.replace(' ', '').lower() for cname in df_gda15.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_gda15['tripid'] = SHORT_NAME + df_gda15['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "df_gda15 = df_gda15.astype({'latitude': 'float', 'longitude': 'float'})\n",
    "df_gda15 = remove_substandard_trips(df_gda15)\n",
    "\n",
    "tqdm.pandas(desc='timestamp')\n",
    "df_gda15['timestamp'] = df_gda15['timestamp'].progress_apply(lambda x: float('nan') if str(x).lower() in ['false', 'nan'] else datetime.fromtimestamp(float(x)).timestamp() )\n",
    "\n",
    "df_gda15 = remove_substandard_trips(df_gda15)\n",
    "df_gda15 = df_calc_basic(df_gda15)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_gda15 = df_gda15[(df_gda15['distance'] != 0) | (df_gda15['end']) | (df_gda15['start'])]\n",
    "\n",
    "print('Shape after: ', df_gda15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (55279, 9)\n",
      "Shape after:  (54244, 16)\n"
     ]
    }
   ],
   "source": [
    "df_gda15_generic = pd.read_csv(f'{DATA_ORIGIN_GDANSK_DIR}/generic_2015.csv')\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_gda15_generic.columns = [cname.replace(' ', '').lower() for cname in df_gda15_generic.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_gda15_generic['tripid'] = SHORT_NAME + df_gda15_generic['tripid'].apply(lambda id: id.replace(' ', ''))\n",
    "df_gda15_generic['distance'] = df_gda15_generic['distance'].astype(float)\n",
    "df_gda15_generic['valid'] = df_gda15_generic[df_gda15_generic['ecc'].notna()]['ecc'].apply(lambda x: False if x == 0 else True)\n",
    "df_gda15_generic['avgspeed'] = df_gda15_generic['avgspeed'].astype(float)\n",
    "df_gda15_generic['tracktype'] = df_gda15_generic[df_gda15_generic['tracktype'].notna()]['tracktype'].apply(val2utf8)\n",
    "df_gda15_generic['male'] = df_gda15_generic[df_gda15_generic['sex'].notna()]['sex'].apply(lambda x: True if str(x).lower() == 'm' else (False if str(x).lower() == 'f' else float('nan')))\n",
    "df_gda15_generic['yearofbirth'] = df_gda15_generic['year'].apply(val2year)\n",
    "df_gda15_generic['profession'] = df_gda15_generic[df_gda15_generic['profession'].notna()]['profession'].apply(val2utf8)\n",
    "df_gda15_generic['frequentuser'] = df_gda15_generic[df_gda15_generic['frequentuser'].notna()]['frequentuser'].apply(lambda x: False if x.lower() == 'no' else True)\n",
    "df_gda15_generic['zip'] = df_gda15_generic[df_gda15_generic['zip'].notna()]['zip'].apply(val2zip)\n",
    "df_gda15_generic['source'] = df_gda15_generic[df_gda15_generic['source'].notna()]['source'].apply(val2utf8)\n",
    "\n",
    "df_gda15_generic.drop(['timestamp', 'startdt', 'ecc', 'sex', 'year', 'distance', 'avgspeed'], axis=1, inplace=True)\n",
    "\n",
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_gda15_generic.shape)\n",
    "\n",
    "df_gda15_generic = df_join_generic_with_gps(df_gda15_generic, df_gda15)\n",
    "\n",
    "print('Shape after: ', df_gda15_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2780/630622996.py:1: DtypeWarning: Columns (1,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_gda16 = pd.read_csv(f'{DATA_ORIGIN_GDANSK_DIR}/detail_2016.csv', encoding='windows-1250', skiprows=[11184484])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (48208935, 8)\n",
      "Removed 1 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "timestamp: 100%|██████████| 48207531/48207531 [01:56<00:00, 415246.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 48204011/48204011 [02:07<00:00, 379088.43it/s]\n",
      "end: 100%|██████████| 48204011/48204011 [02:08<00:00, 375933.86it/s]\n",
      "distance: 100%|██████████| 48204011/48204011 [04:14<00:00, 189187.69it/s]\n",
      "duration: 100%|██████████| 48204011/48204011 [02:20<00:00, 343815.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (40168472, 14)\n"
     ]
    }
   ],
   "source": [
    "df_gda16 = pd.read_csv(f'{DATA_ORIGIN_GDANSK_DIR}/detail_2016.csv', encoding='windows-1250', skiprows=[11184484])\n",
    "\n",
    "print('Shape before: ', df_gda16.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_gda16.columns = [cname.replace(' ', '').lower() for cname in df_gda16.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_gda16['tripid'] = SHORT_NAME + df_gda16['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "df_gda16 = df_gda16.astype({'latitude': 'float', 'longitude': 'float'})\n",
    "df_gda16 = remove_substandard_trips(df_gda16)\n",
    "\n",
    "tqdm.pandas(desc='timestamp')\n",
    "df_gda16['timestamp'] = df_gda16['timestamp'].progress_apply(lambda x: float('nan') if str(x).lower() in ['false', 'nan'] else datetime.fromtimestamp(float(x)).timestamp() )\n",
    "\n",
    "df_gda16 = remove_substandard_trips(df_gda16)\n",
    "df_gda16 = df_calc_basic(df_gda16)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_gda16 = df_gda16[(df_gda16['distance'] != 0) | (df_gda16['end']) | (df_gda16['start'])]\n",
    "\n",
    "print('Shape after: ', df_gda16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (88992, 12)\n",
      "Shape after:  (85872, 19)\n"
     ]
    }
   ],
   "source": [
    "df_gda16_generic = pd.read_csv(f'{DATA_ORIGIN_GDANSK_DIR}/generic_2016.csv')\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_gda16_generic.columns = [cname.replace(' ', '').lower() for cname in df_gda16_generic.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_gda16_generic['tripid'] = SHORT_NAME + df_gda16_generic['tripid'].apply(lambda x: x.replace(' ', ''))\n",
    "df_gda16_generic['distance'] = df_gda16_generic['distance'].astype(float)\n",
    "df_gda16_generic['valid'] = df_gda16_generic[df_gda16_generic['ecc'].notna()]['ecc'].apply(lambda x: False if x == 0 else True)\n",
    "df_gda16_generic['avgspeed'] = df_gda16_generic['avgspeed'].astype(float)\n",
    "df_gda16_generic['tracktype'] = df_gda16_generic[df_gda16_generic['tracktype'].notna()]['tracktype'].apply(val2utf8)\n",
    "df_gda16_generic['male'] = df_gda16_generic[df_gda16_generic['sex'].notna()]['sex'].apply(lambda x: True if str(x).lower() == 'm' else (False if str(x).lower() == 'f' else float('nan')))\n",
    "df_gda16_generic['yearofbirth'] = df_gda16_generic['year'].apply(val2year)\n",
    "df_gda16_generic['profession'] = df_gda16_generic[df_gda16_generic['profession'].notna()]['profession'].apply(val2utf8)\n",
    "df_gda16_generic['frequentuser'] = df_gda16_generic[df_gda16_generic['frequentuser'].notna()]['frequentuser'].apply(lambda x: False if x.lower() in ['no', 'nie'] else False)\n",
    "df_gda16_generic['zip'] = df_gda16_generic[df_gda16_generic['zip'].notna()]['zip'].apply(val2zip)\n",
    "df_gda16_generic['source'] = df_gda16_generic[df_gda16_generic['source'].notna()]['source'].apply(val2utf8)\n",
    "df_gda16_generic['typeofbike'] = df_gda16_generic[df_gda16_generic['typeofbike'].notna()]['typeofbike'].apply(val2utf8)\n",
    "df_gda16_generic['typeoftrip'] = df_gda16_generic[df_gda16_generic['tipeoftrip'].notna()]['tipeoftrip'].apply(val2utf8)\n",
    "\n",
    "df_gda16_generic.drop(['timestamp', 'startdt', 'ecc', 'sex', 'year', 'distance', 'avgspeed'], axis=1, inplace=True)\n",
    "\n",
    "''' Joinig generic data with gps data '''\n",
    "print('Shape before: ', df_gda16_generic.shape)\n",
    "\n",
    "df_gda16_generic = df_join_generic_with_gps(df_gda16_generic, df_gda16)\n",
    "\n",
    "print('Shape after: ', df_gda16_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before. 2015: (22495726, 15) 2016: (40168472, 14)\n",
      "Shape after. 2015: (22326294, 5) 2016: (39343640, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before. 2015:', df_gda15.shape, '2016:', df_gda16.shape)\n",
    "\n",
    "df_gda15 = df_gda15[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_gda15 = df_gda15[df_gda15['tripid'].isin(df_gda15_generic['tripid'].tolist())]\n",
    "\n",
    "df_gda16 = df_gda16[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_gda16 = df_gda16[df_gda16['tripid'].isin(df_gda16_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after. 2015:', df_gda15.shape, '2016:', df_gda16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before. 2015: (54244, 16) 2016: (85872, 19)\n",
      "Shape before. 2015: (54244, 15) 2016: (85872, 17)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before. 2015:', df_gda15_generic.shape, '2016:', df_gda16_generic.shape)\n",
    "\n",
    "df_gda15_generic = df_gda15_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'tracktype', 'source', 'profession', 'male', 'frequentuser', 'zip', 'yearofbirth', 'valid']]\n",
    "\n",
    "df_gda16_generic = df_gda16_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts', 'tracktype', 'typeofbike', 'typeoftrip', 'source', 'profession', 'male', 'frequentuser', 'zip', 'yearofbirth', 'valid']]\n",
    "\n",
    "print('Shape before. 2015:', df_gda15_generic.shape, '2016:', df_gda16_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets concatenaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61669934 entries, 0 to 61669933\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   tripid     object \n",
      " 1   latitude   float64\n",
      " 2   longitude  float64\n",
      " 3   timestamp  float64\n",
      " 4   start      bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_gda = pd.concat([df_gda15, df_gda16], ignore_index=True)\n",
    "df_gda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140116 entries, 0 to 140115\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   tripid                   140116 non-null  object \n",
      " 1   speedmax                 140116 non-null  float64\n",
      " 2   speedavg_excluding_time  140116 non-null  float64\n",
      " 3   speedavg_over_time       140116 non-null  float64\n",
      " 4   distance                 140116 non-null  float64\n",
      " 5   startts                  140116 non-null  float64\n",
      " 6   endts                    140116 non-null  float64\n",
      " 7   tracktype                140116 non-null  object \n",
      " 8   source                   140114 non-null  object \n",
      " 9   profession               104634 non-null  object \n",
      " 10  male                     120196 non-null  object \n",
      " 11  frequentuser             140116 non-null  bool   \n",
      " 12  zip                      81446 non-null   object \n",
      " 13  yearofbirth              118068 non-null  object \n",
      " 14  valid                    140116 non-null  bool   \n",
      " 15  typeofbike               42056 non-null   object \n",
      " 16  typeoftrip               42021 non-null   object \n",
      "dtypes: bool(2), float64(6), object(9)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_gda_generic = pd.concat([df_gda15_generic, df_gda16_generic], ignore_index=True)\n",
    "df_gda_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gda.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_gda_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SW Sodertalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from _lib.settings import DATA_ORIGIN_SODERTALIE_DIR\n",
    "\n",
    "\n",
    "SHORT_NAME = 'sod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (594498, 8)\n",
      "Removed 0 substandard trips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start: 100%|██████████| 594498/594498 [00:01<00:00, 343192.42it/s]\n",
      "end: 100%|██████████| 594498/594498 [00:01<00:00, 373535.29it/s]\n",
      "distance: 100%|██████████| 594498/594498 [00:03<00:00, 188749.16it/s]\n",
      "duration: 100%|██████████| 594498/594498 [00:01<00:00, 334384.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after:  (457312, 11)\n"
     ]
    }
   ],
   "source": [
    "df_sod = pd.read_csv(f'{DATA_ORIGIN_SODERTALIE_DIR}/sodertalje_detail.csv')\n",
    "\n",
    "print('Shape before: ', df_sod.shape)\n",
    "\n",
    "''' Column names normalization '''\n",
    "df_sod.columns = [cname.replace(' ', '').lower() for cname in df_sod.columns]\n",
    "\n",
    "''' Column data normalization '''\n",
    "df_sod['tripid'] = SHORT_NAME + df_sod['tripid'].astype(str).replace(' ', '')\n",
    "\n",
    "tqdm.pandas(desc='timestamp')\n",
    "df_sod['timestamp'] = df_sod['timestamp'].apply(lambda x: datetime.fromtimestamp(float(x)).timestamp() )\n",
    "\n",
    "df_sod.drop(['altitude', 'distance', 'speed', 'type'], axis=1, inplace=True)\n",
    "\n",
    "df_sod = df_sod.astype({'latitude': 'float', 'longitude': 'float'})\n",
    "\n",
    "df_sod = remove_substandard_trips(df_sod)\n",
    "df_sod = df_calc_basic(df_sod)\n",
    "\n",
    "''' Removing points with 0 distance passed '''\n",
    "df_sod = df_sod[(df_sod['distance'] != 0) | (df_sod['end']) | (df_sod['start'])]\n",
    "\n",
    "print('Shape after: ', df_sod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (1487, 7)\n",
      "Shape after:  (1466, 8)\n"
     ]
    }
   ],
   "source": [
    "df_sod_generic = calc_context(df_sod)\n",
    "\n",
    "print('Shape before: ', df_sod_generic.shape)\n",
    "\n",
    "df_sod_generic.drop_duplicates(subset=list(set(df_sod_generic.columns.tolist()) - set(['startts', 'endts'])), keep='first', inplace=True)\n",
    "\n",
    "df_sod_generic = df_sod_generic.reset_index(inplace=False)\n",
    "\n",
    "print('Shape after: ', df_sod_generic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overall columns & records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (457312, 11)\n",
      "Shape after: (455007, 5)\n"
     ]
    }
   ],
   "source": [
    "''' DETAIL '''\n",
    "\n",
    "print('Shape before:', df_sod.shape)\n",
    "\n",
    "df_sod = df_sod[['tripid', 'latitude', 'longitude', 'timestamp', 'start']]\n",
    "df_sod = df_sod[df_sod['tripid'].isin(df_sod_generic['tripid'].tolist())]\n",
    "\n",
    "print('Shape after:', df_sod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (1466, 8)\n",
      "Shape after: (1466, 7)\n"
     ]
    }
   ],
   "source": [
    "''' GENERIC '''\n",
    "\n",
    "print('Shape before:', df_sod_generic.shape)\n",
    "\n",
    "df_sod_generic = df_sod_generic[['tripid', 'speedmax', 'speedavg_excluding_time', 'speedavg_over_time', 'distance', 'startts', 'endts']]\n",
    "\n",
    "print('Shape after:', df_sod_generic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 455007 entries, 0 to 594497\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   tripid     455007 non-null  object \n",
      " 1   latitude   455007 non-null  float64\n",
      " 2   longitude  455007 non-null  float64\n",
      " 3   timestamp  455007 non-null  float64\n",
      " 4   start      455007 non-null  bool   \n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 17.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1466 entries, 0 to 1465\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tripid                   1466 non-null   object \n",
      " 1   speedmax                 1466 non-null   float64\n",
      " 2   speedavg_excluding_time  1466 non-null   float64\n",
      " 3   speedavg_over_time       1466 non-null   float64\n",
      " 4   distance                 1466 non-null   float64\n",
      " 5   startts                  1466 non-null   float64\n",
      " 6   endts                    1466 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 80.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sod_generic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sod.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}.csv', index=False, sep=';')\n",
    "df_sod_generic.to_csv(f'{DATA_AFTER_PREPARATION_DIR}/{SHORT_NAME}_generic.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43f41945229dceb886551289960f1b9a44b0b32f7093d7c7f71fbe0a48174f8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
